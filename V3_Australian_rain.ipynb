{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  *** DRAFT ***\n",
    "##### Author: Omer Nivron\n",
    "##### Date: 04/09/19\n",
    "#####  Data source: https://www.kaggle.com/jsphyg/weather-dataset-rattle-package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aus_rain_cleanup import *\n",
    "from aus_rain_feat_eng import *\n",
    "from aus_rain_modeling import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "australian_rain_df = pd.read_csv('weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report - Australian rain prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Results:    ~85% success rate in predicting tomorrow's rain outcome (still plenty of potential)\n",
    "####                      - The most important features to predict rain are locations and wind directions. Whether it rained today doesn't seem very important from the model (however it might just be correlated with another variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of Rainfall in January 2010\n",
    "\n",
    "![Rainfall Map](rainfall_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions\n",
    " - Missing values are reasonably replaced by mode and median per month and location for categorical and numeric columns respictively \n",
    " - It is valid to drop columns with missing value share greater than 0.35\n",
    " - Inheirt Tree model assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open issues/ problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model is overfitting: learning can't generalize well to new data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis method explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis included cleaning data with the main issue being plenty missing values; Grouping by year, month and location, the median was used for numeric columns since it's more reliable when data isn't symmetric; The mode was used for categorical columns. Other cleaning procedures included formating (e.g. string to date). I then transformed categorical variables to one-hot encodings since the model can't handle strings. Then I split the data to training data (everything prior to 2015) and test data that was never seen by the model (2015 onwards) and is used to asses results on unseen data. After all data was model ready I ran it once with a decision tree model and a random forest model. Currently our metric is misclassification rate: how many times our model got it wrong divided by size of data (this metric might be misleading and future work should consider other options)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why did I choose the tree based models for the task ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can deal better than other models with missing values (depending implementation)\n",
    "- No need to normalize data or make any transformations\n",
    "- Quick predictions \n",
    "- Robust to outliers\n",
    "- Easy interpretability (variable importance and selection)\n",
    "- Empirically strong results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated dates here!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mE:\\College\\Programs\\Anaconda Original\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:438\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mE:\\College\\Programs\\Anaconda Original\\lib\\site-packages\\pandas\\core\\algorithms.py:763\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    761\u001b[0m         na_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 763\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mE:\\College\\Programs\\Anaconda Original\\lib\\site-packages\\pandas\\core\\algorithms.py:560\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    559\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 560\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m codes \u001b[38;5;241m=\u001b[39m ensure_platform_int(codes)\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5394\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5310\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m australian_rain_df\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m######\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m###### Feature engineering ######\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m australian_rain_df \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_to_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43maustralian_rain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m######\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m###### Modelling ######\u001b[39;00m\n\u001b[0;32m      9\u001b[0m feat_importance, results_pd \u001b[38;5;241m=\u001b[39m model(australian_rain_df)\n",
      "File \u001b[1;32m~\\fol\\pushing_git\\aus_rain_feat_eng.py:4\u001b[0m, in \u001b[0;36mtransform_to_dummies\u001b[1;34m(df, cols)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_to_dummies\u001b[39m(df, cols):\n\u001b[1;32m----> 4\u001b[0m     dummies \u001b[38;5;241m=\u001b[39m  \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(cols, axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, dummies], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mE:\\College\\Programs\\Anaconda Original\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:977\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    973\u001b[0m     with_dummies \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39mdtypes_to_encode)]\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (col, pre, sep) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_to_encode\u001b[38;5;241m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[1;32m--> 977\u001b[0m     dummy \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dummies_1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix_sep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m     with_dummies\u001b[38;5;241m.\u001b[39mappend(dummy)\n\u001b[0;32m    987\u001b[0m result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mE:\\College\\Programs\\Anaconda Original\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:1013\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;66;03m# Series avoids inconsistent NaN handling\u001b[39;00m\n\u001b[1;32m-> 1013\u001b[0m codes, levels \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_from_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1016\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "File \u001b[1;32mE:\\College\\Programs\\Anaconda Original\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:2854\u001b[0m, in \u001b[0;36mfactorize_from_iterable\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   2849\u001b[0m     codes \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcodes\n\u001b[0;32m   2850\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2851\u001b[0m     \u001b[38;5;66;03m# The value of ordered is irrelevant since we don't use cat as such,\u001b[39;00m\n\u001b[0;32m   2852\u001b[0m     \u001b[38;5;66;03m# but only the resulting categories, the order of which is independent\u001b[39;00m\n\u001b[0;32m   2853\u001b[0m     \u001b[38;5;66;03m# from ordered. Set ordered to False as default. See GH #15457\u001b[39;00m\n\u001b[1;32m-> 2854\u001b[0m     cat \u001b[38;5;241m=\u001b[39m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2855\u001b[0m     categories \u001b[38;5;241m=\u001b[39m cat\u001b[38;5;241m.\u001b[39mcategories\n\u001b[0;32m   2856\u001b[0m     codes \u001b[38;5;241m=\u001b[39m cat\u001b[38;5;241m.\u001b[39mcodes\n",
      "File \u001b[1;32mE:\\College\\Programs\\Anaconda Original\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:440\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[0;32m    438\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m factorize(values, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 440\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mordered:\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;66;03m# raise, as we don't have a sortable data structure and so\u001b[39;00m\n\u001b[0;32m    443\u001b[0m         \u001b[38;5;66;03m# the user should give us one by specifying categories\u001b[39;00m\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    445\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not ordered, please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplicitly specify the categories order \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby passing in a categories argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32mE:\\College\\Programs\\Anaconda Original\\lib\\site-packages\\pandas\\core\\algorithms.py:763\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m         na_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 763\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    768\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    769\u001b[0m         uniques, codes, na_sentinel\u001b[38;5;241m=\u001b[39mna_sentinel, assume_unique\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    770\u001b[0m     )\n",
      "File \u001b[1;32mE:\\College\\Programs\\Anaconda Original\\lib\\site-packages\\pandas\\core\\algorithms.py:560\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    557\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_data_algo(values)\n\u001b[0;32m    559\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 560\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m codes \u001b[38;5;241m=\u001b[39m ensure_platform_int(codes)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5394\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5310\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "####### Cleanup #######\n",
    "cat_cols, num_cols, australian_rain_df = cleanup(australian_rain_df)\n",
    "df = australian_rain_df\n",
    "######\n",
    "###### Feature engineering ######\n",
    "australian_rain_df = transform_to_dummies(australian_rain_df, list(cat_cols) + ['Location'])\n",
    "######\n",
    "###### Modelling ######\n",
    "feat_importance, results_pd = model(australian_rain_df)\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue;\"> USER INPUT -  Change location/month to see other distributions  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'Adelaide'\n",
    "mon = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move Graph Code Below to Function Notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example distribution to why we use the median as a missing value replacement \n",
    "boxprops = dict(color='b')\n",
    "medianprops = dict(color='b')\n",
    "\n",
    "\n",
    "\n",
    "bp = df[df['Location'] == loc].boxplot(column='WindGustSpeed', by =['Month'], figsize = (12, 5), \n",
    "                                      boxprops = boxprops, medianprops = medianprops, return_type = 'dict')\n",
    "\n",
    "plt.ylabel('Wind Speed (km / h)', fontsize = 16)\n",
    "plt.xlabel('Month', fontsize = 14)\n",
    "plt.xticks(list(range(1,13)), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'July', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.suptitle('')\n",
    "plt.title('Wind Speed by Month in Adelaide', fontsize = 20)\n",
    "\n",
    "[[item.set_color('b') for item in bp[key]['boxes']] for key in bp.keys()]\n",
    "[[item.set_color('b') for item in bp[key]['fliers']] for key in bp.keys()]\n",
    "[[item.set_color('b') for item in bp[key]['medians']] for key in bp.keys()]\n",
    "[[item.set_markerfacecolor('b') for item in bp[key]['means']] for key in bp.keys()]\n",
    "[[item.set_color('b') for item in bp[key]['whiskers']] for key in bp.keys()]\n",
    "[[item.set_color('b') for item in bp[key]['caps']] for key in bp.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2 , figsize=(18, 11))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(df.loc[:,'Pressure9am'], df.loc[:, 'Pressure3pm'], color='b')\n",
    "plt.title('Correlation plot between air pressure at 9am (x) to air pressure at 3pm (y)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(df.loc[:,'Humidity9am'], df.loc[:, 'Rainfall'], color='g')\n",
    "plt.title('Correlation plot between humidity (x) at 9am to rainfall (y)')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(df.loc[:,'Humidity9am'], df.loc[:, 'Temp9am'], color='y')\n",
    "plt.title('Correlation plot between humidity (x) to temperture at 9am (y)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(df.loc[:,'Temp3pm'], df.loc[:, 'MaxTemp'], color='r')\n",
    "plt.title('Correlation plot between temperture (x) at 3pm to max temperture (y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical varibales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_gust_bar_data = df.loc[df['Location'] == loc, ['Location', 'WindGustDir', 'Month']].groupby(['WindGustDir','Month']).count().reset_index()\n",
    "wind_dir3pm_bar_data = df.loc[df['Location'] == loc, ['Location', 'WindDir3pm', 'Month']].groupby(['WindDir3pm','Month']).count().reset_index()\n",
    "wind_dir9am_bar_data = df.loc[df['Location'] == loc, ['Location', 'WindDir9am', 'Month']].groupby(['WindDir9am','Month']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2 , figsize=(18, 11))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(wind_gust_bar_data.loc[wind_gust_bar_data['Month'] == mon,'WindGustDir'], wind_gust_bar_data.loc[wind_gust_bar_data['Month'] == 4, 'Location'].sort_values(ascending = False), color='b')\n",
    "plt.title('Count of wind direction gust at Adelaide during April')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(wind_dir9am_bar_data.loc[wind_dir9am_bar_data ['Month'] == mon,'WindDir9am'], wind_dir9am_bar_data.loc[wind_dir9am_bar_data['Month'] == 4, 'Location'].sort_values(ascending = False), color= 'g')\n",
    "plt.title('Count of wind direction 9am at Adelaide during April')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(wind_dir3pm_bar_data.loc[wind_dir3pm_bar_data['Month'] == mon,'WindDir3pm'], wind_dir3pm_bar_data.loc[wind_dir3pm_bar_data['Month'] == 4, 'Location'].sort_values(ascending = False), color= 'y')\n",
    "plt.title('Count of wind direction 3pm at Adelaide during April')\n",
    "\n",
    "fig.delaxes(axes[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do's "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Exploration:\n",
    "1. Check for areas where it never rains and drop from dataset \n",
    "2. Check the correlations of variables with rain today status \n",
    " \n",
    "        \n",
    " - Model : \n",
    "1. Add a baseline model for comparison \n",
    "2. Hyperparameter optimization\n",
    "3. Consider logistic regression model\n",
    "4. Balance data (sampling)\n",
    "5. Add true-pos and false-pos metrics\n",
    "6. Add ROC curve\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
